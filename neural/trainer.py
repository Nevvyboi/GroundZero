"""
GroundZero Neural Trainer v2.0 - Advanced Training System
=========================================================
Production-grade continual learning trainer.

UPGRADES FROM v1.0:
- Gradient accumulation for effective larger batches
- Curriculum learning (easy to hard)
- Learning rate scheduling with warmup
- Data backfilling when changing model sizes
- Better experience replay with prioritized sampling
- Online EWC with Fisher information
- Mixed precision training support
- Distributed training ready
- Comprehensive checkpointing
- Training metrics and visualization
- Progress callbacks for CLI/UI

Designed for continuous learning without catastrophic forgetting.
"""

import os
import sys
import time
import random
import threading
import pickle
import numpy as np
from typing import List, Dict, Any, Optional, Tuple, Callable
from collections import deque
from pathlib import Path
from dataclasses import dataclass, field
from datetime import datetime
import json

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torch.cuda.amp import GradScaler, autocast

from .transformer import GroundZeroTransformer, TransformerConfig
from .tokenizer import BPETokenizer


@dataclass
class TrainerConfig:
    """Enhanced training configuration"""
    # Model
    model_size: str = "small"
    
    # Training
    batch_size: int = 8
    gradient_accumulation_steps: int = 4
    learning_rate: float = 3e-4
    min_learning_rate: float = 1e-5
    weight_decay: float = 0.01
    max_grad_norm: float = 1.0
    warmup_steps: int = 500
    max_steps: int = 100000
    
    # Scheduler
    lr_scheduler: str = "cosine"  # cosine, linear, constant
    warmup_ratio: float = 0.1
    
    # Continual learning
    replay_buffer_size: int = 50000
    replay_ratio: float = 0.3
    ewc_lambda: float = 500.0
    prioritized_replay: bool = True
    curriculum_learning: bool = True
    
    # Mixed precision
    use_mixed_precision: bool = True
    
    # Checkpointing
    save_every_steps: int = 1000
    keep_checkpoints: int = 5
    checkpoint_dir: Path = Path("checkpoints")
    
    # Hardware
    device: str = "auto"
    num_workers: int = 4


class PrioritizedReplayBuffer:
    """
    Prioritized Experience Replay Buffer
    
    Samples experiences based on their TD error / loss.
    Important experiences (higher loss) are replayed more often.
    """
    
    def __init__(self, max_size: int = 50000, alpha: float = 0.6):
        self.max_size = max_size
        self.alpha = alpha  # Priority exponent
        
        self.buffer: List[Dict] = []
        self.priorities: np.ndarray = np.zeros(max_size, dtype=np.float32)
        self.position = 0
        self.size = 0
    
    def add(self, sequence: List[int], priority: float = 1.0, metadata: Dict = None):
        """Add sequence with priority"""
        entry = {
            'sequence': sequence,
            'priority': priority,
            'metadata': metadata or {},
            'timestamp': time.time()
        }
        
        if self.size < self.max_size:
            self.buffer.append(entry)
            self.priorities[self.size] = priority ** self.alpha
            self.size += 1
        else:
            self.buffer[self.position] = entry
            self.priorities[self.position] = priority ** self.alpha
        
        self.position = (self.position + 1) % self.max_size
    
    def add_batch(self, sequences: List[List[int]], priorities: List[float] = None):
        """Add multiple sequences"""
        if priorities is None:
            priorities = [1.0] * len(sequences)
        
        for seq, pri in zip(sequences, priorities):
            self.add(seq, pri)
    
    def sample(self, n: int) -> Tuple[List[List[int]], List[int], List[float]]:
        """Sample n sequences based on priority"""
        if self.size == 0:
            return [], [], []
        
        n = min(n, self.size)
        
        # Compute sampling probabilities
        probs = self.priorities[:self.size] / self.priorities[:self.size].sum()
        
        # Sample indices
        indices = np.random.choice(self.size, size=n, replace=False, p=probs)
        
        sequences = [self.buffer[i]['sequence'] for i in indices]
        weights = [(self.size * probs[i]) ** -0.4 for i in indices]  # IS weights
        
        # Normalize weights
        max_weight = max(weights)
        weights = [w / max_weight for w in weights]
        
        return sequences, list(indices), weights
    
    def update_priorities(self, indices: List[int], priorities: List[float]):
        """Update priorities for sampled indices"""
        for idx, pri in zip(indices, priorities):
            if 0 <= idx < self.size:
                self.priorities[idx] = (pri + 1e-6) ** self.alpha
    
    def __len__(self):
        return self.size
    
    def save(self, path: Path):
        """Save buffer to disk"""
        data = {
            'buffer': self.buffer[:self.size],
            'priorities': self.priorities[:self.size].tolist(),
            'position': self.position,
            'size': self.size
        }
        with open(path, 'wb') as f:
            pickle.dump(data, f)
    
    def load(self, path: Path):
        """Load buffer from disk"""
        if not path.exists():
            return
        
        with open(path, 'rb') as f:
            data = pickle.load(f)
        
        self.buffer = data['buffer']
        self.priorities = np.array(data['priorities'] + [0.0] * (self.max_size - len(data['priorities'])))
        self.position = data['position']
        self.size = data['size']


class OnlineEWC:
    """
    Online Elastic Weight Consolidation
    
    Maintains running estimate of Fisher information.
    Prevents forgetting by penalizing changes to important weights.
    """
    
    def __init__(self, model: nn.Module, lambda_: float = 500.0, gamma: float = 0.95):
        self.model = model
        self.lambda_ = lambda_
        self.gamma = gamma  # Decay factor for online EWC
        
        # Running Fisher information
        self.fisher: Dict[str, torch.Tensor] = {}
        self.optimal_params: Dict[str, torch.Tensor] = {}
        
        self.n_updates = 0
        self.is_initialized = False
    
    @torch.no_grad()
    def update_fisher(self, dataloader: DataLoader, num_batches: int = 50):
        """Update Fisher information from data"""
        self.model.eval()
        device = next(self.model.parameters()).device
        
        # Compute new Fisher estimates
        new_fisher = {n: torch.zeros_like(p) for n, p in self.model.named_parameters() if p.requires_grad}
        
        samples = 0
        for i, (inputs, targets) in enumerate(dataloader):
            if i >= num_batches:
                break
            
            inputs, targets = inputs.to(device), targets.to(device)
            
            self.model.zero_grad()
            outputs = self.model(inputs, labels=targets)
            loss = outputs['loss']
            loss.backward()
            
            for name, param in self.model.named_parameters():
                if param.grad is not None:
                    new_fisher[name] += param.grad.pow(2)
            
            samples += inputs.size(0)
        
        # Normalize
        for name in new_fisher:
            new_fisher[name] /= max(samples, 1)
        
        # Online update
        if self.is_initialized:
            for name in self.fisher:
                self.fisher[name] = self.gamma * self.fisher[name] + (1 - self.gamma) * new_fisher[name]
                self.optimal_params[name] = self.gamma * self.optimal_params[name] + \
                                            (1 - self.gamma) * self.model.state_dict()[name].clone()
        else:
            self.fisher = new_fisher
            self.optimal_params = {n: p.clone() for n, p in self.model.named_parameters() if p.requires_grad}
            self.is_initialized = True
        
        self.n_updates += 1
        self.model.train()
    
    def penalty(self) -> torch.Tensor:
        """Compute EWC penalty"""
        if not self.is_initialized:
            return torch.tensor(0.0)
        
        device = next(self.model.parameters()).device
        loss = torch.tensor(0.0, device=device)
        
        for name, param in self.model.named_parameters():
            if name in self.fisher and param.requires_grad:
                # Move fisher and optimal params to correct device
                fisher = self.fisher[name].to(device)
                optimal = self.optimal_params[name].to(device)
                loss += (fisher * (param - optimal).pow(2)).sum()
        
        return self.lambda_ * loss


class TextDataset(Dataset):
    """Enhanced text dataset with curriculum learning support"""
    
    def __init__(self, token_ids: List[List[int]], max_seq_len: int = 2048,
                 pad_id: int = 0, curriculum: bool = False):
        self.sequences = []
        self.difficulties = []
        self.max_seq_len = max_seq_len
        self.pad_id = pad_id
        self.curriculum = curriculum
        
        # Split into chunks
        for ids in token_ids:
            for i in range(0, len(ids) - 1, max_seq_len):
                chunk = ids[i:i + max_seq_len + 1]
                if len(chunk) > 10:
                    self.sequences.append(chunk)
                    # Difficulty = sequence length (longer = harder)
                    self.difficulties.append(len(chunk))
        
        # Sort by difficulty for curriculum learning
        if curriculum and self.sequences:
            sorted_pairs = sorted(zip(self.difficulties, self.sequences))
            self.difficulties, self.sequences = zip(*sorted_pairs)
            self.difficulties = list(self.difficulties)
            self.sequences = list(self.sequences)
    
    def __len__(self):
        return len(self.sequences)
    
    def __getitem__(self, idx):
        seq = self.sequences[idx]
        
        # Pad
        if len(seq) < self.max_seq_len + 1:
            seq = seq + [self.pad_id] * (self.max_seq_len + 1 - len(seq))
        
        return torch.tensor(seq[:-1]), torch.tensor(seq[1:])


class CurriculumSampler:
    """Sampler for curriculum learning - starts with easy samples"""
    
    def __init__(self, dataset: TextDataset, num_epochs: int = 10):
        self.dataset = dataset
        self.num_epochs = num_epochs
        self.current_epoch = 0
    
    def __iter__(self):
        n = len(self.dataset)
        
        # Progress: what fraction of data to use
        progress = min(1.0, (self.current_epoch + 1) / self.num_epochs)
        cutoff = int(n * progress)
        
        # Sample from available range
        indices = list(range(cutoff))
        random.shuffle(indices)
        
        return iter(indices)
    
    def __len__(self):
        n = len(self.dataset)
        progress = min(1.0, (self.current_epoch + 1) / self.num_epochs)
        return int(n * progress)
    
    def step(self):
        self.current_epoch += 1


class NeuralTrainer:
    """
    Advanced Neural Trainer v2.0
    
    Features:
    - Gradient accumulation
    - Curriculum learning
    - Prioritized replay
    - Online EWC
    - Mixed precision
    - Learning rate scheduling
    - Data backfilling for model size changes
    - Comprehensive logging
    """
    
    def __init__(self, config: TrainerConfig, data_dir: Path):
        self.config = config
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # Determine device
        if config.device == "auto":
            if torch.cuda.is_available():
                self.device = torch.device("cuda")
            elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                self.device = torch.device("mps")
            else:
                self.device = torch.device("cpu")
        else:
            self.device = torch.device(config.device)
        
        # Create model
        model_config = self._get_model_config(config.model_size)
        self.model = GroundZeroTransformer(model_config).to(self.device)
        
        # Tokenizer
        self.tokenizer = BPETokenizer(vocab_size=model_config.vocab_size)
        
        # Optimizer
        self.optimizer = optim.AdamW(
            self.model.parameters(),
            lr=config.learning_rate,
            weight_decay=config.weight_decay,
            betas=(0.9, 0.95)
        )
        
        # Scheduler
        self.scheduler = self._create_scheduler()
        
        # Mixed precision
        self.scaler = GradScaler() if config.use_mixed_precision and self.device.type == 'cuda' else None
        
        # Replay buffer
        self.replay_buffer = PrioritizedReplayBuffer(config.replay_buffer_size)
        
        # EWC
        self.ewc = OnlineEWC(self.model, config.ewc_lambda)
        
        # Training state
        self.global_step = 0
        self.total_tokens_trained = 0
        self.training_history: List[Dict] = []
        
        # Background training
        self._training_queue = deque(maxlen=10000)
        self._training_thread: Optional[threading.Thread] = None
        self._stop_training = threading.Event()
        self._is_training = False
        
        # Paths
        self.model_path = self.data_dir / "model.pt"
        self.tokenizer_path = self.data_dir / "tokenizer.json"
        self.state_path = self.data_dir / "trainer_state.json"
        self.buffer_path = self.data_dir / "replay_buffer.pkl"
        
        # Progress callback
        self.on_progress: Optional[Callable] = None
        
        # Load if exists
        self._load_state()
    
    def _get_model_config(self, size: str) -> TransformerConfig:
        """Get model config by size name"""
        configs = {
            'nano': TransformerConfig.nano(),
            'tiny': TransformerConfig.tiny(),
            'small': TransformerConfig.small(),
            'medium': TransformerConfig.medium(),
            'large': TransformerConfig.large(),
            'xl': TransformerConfig.xl(),
            'xxl': TransformerConfig.xxl()
        }
        return configs.get(size.lower(), TransformerConfig.small())
    
    def _create_scheduler(self):
        """Create learning rate scheduler"""
        if self.config.lr_scheduler == "cosine":
            return optim.lr_scheduler.CosineAnnealingLR(
                self.optimizer,
                T_max=self.config.max_steps,
                eta_min=self.config.min_learning_rate
            )
        elif self.config.lr_scheduler == "linear":
            return optim.lr_scheduler.LinearLR(
                self.optimizer,
                start_factor=1.0,
                end_factor=self.config.min_learning_rate / self.config.learning_rate,
                total_iters=self.config.max_steps
            )
        else:
            return optim.lr_scheduler.ConstantLR(self.optimizer, factor=1.0)
    
    def _load_state(self):
        """Load training state"""
        if self.model_path.exists():
            try:
                self.model = GroundZeroTransformer.load(self.model_path, str(self.device))
                print(f"      â”œâ”€  âœ“ Loaded model: {self.model.n_params:,} params")
            except Exception as e:
                print(f"      â”œâ”€  âš  Model load failed: {e}")
        
        if self.tokenizer_path.exists():
            try:
                self.tokenizer = BPETokenizer.load(self.tokenizer_path)
                print(f"      â”œâ”€  âœ“ Loaded tokenizer: {len(self.tokenizer)} tokens")
            except Exception as e:
                print(f"      â”œâ”€  âš  Tokenizer load failed: {e}")
        
        if self.buffer_path.exists():
            try:
                self.replay_buffer.load(self.buffer_path)
                print(f"      â”œâ”€  âœ“ Loaded replay buffer: {len(self.replay_buffer)} samples")
            except Exception as e:
                print(f"      â”œâ”€  âš  Buffer load failed: {e}")
        
        if self.state_path.exists():
            try:
                with open(self.state_path, 'r') as f:
                    state = json.load(f)
                self.global_step = state.get('global_step', 0)
                self.total_tokens_trained = state.get('total_tokens_trained', 0)
                self.training_history = state.get('training_history', [])
            except Exception as e:
                print(f"      â”œâ”€  âš  State load failed: {e}")
    
    def _save_state(self):
        """Save training state"""
        state = {
            'global_step': self.global_step,
            'total_tokens_trained': self.total_tokens_trained,
            'training_history': self.training_history[-1000:],  # Keep last 1000
            'config': {
                'model_size': self.config.model_size,
                'learning_rate': self.config.learning_rate
            }
        }
        with open(self.state_path, 'w') as f:
            json.dump(state, f, indent=2)
    
    def change_model_size(self, new_size: str, backfill: bool = True) -> Dict[str, Any]:
        """
        Change model size with optional data backfilling
        
        Args:
            new_size: New model size
            backfill: If True, transfer knowledge from old model
        
        Returns:
            Migration statistics
        """
        old_config = self.model.config
        old_model = self.model
        
        # Create new model
        new_config = self._get_model_config(new_size)
        new_model = GroundZeroTransformer(new_config).to(self.device)
        
        stats = {
            'old_size': self.config.model_size,
            'new_size': new_size,
            'old_params': old_model.n_params,
            'new_params': new_model.n_params,
            'backfilled': False
        }
        
        if backfill and len(self.replay_buffer) > 0:
            print(f"ðŸ”„ Backfilling data from {self.config.model_size} to {new_size}...")
            
            # Transfer tokenizer (vocabularies should match if same tokenizer)
            # Retrain on replay buffer data
            sequences, _, _ = self.replay_buffer.sample(min(len(self.replay_buffer), 10000))
            
            if sequences:
                # Create dataset from replay buffer
                dataset = TextDataset(sequences, new_config.max_seq_len, self.tokenizer.pad_id)
                
                if len(dataset) > 0:
                    # Quick training pass
                    dataloader = DataLoader(
                        dataset,
                        batch_size=self.config.batch_size,
                        shuffle=True,
                        drop_last=True
                    )
                    
                    # Train new model briefly
                    new_model.train()
                    optimizer = optim.AdamW(new_model.parameters(), lr=self.config.learning_rate)
                    
                    steps = 0
                    max_steps = 500
                    
                    for inputs, targets in dataloader:
                        if steps >= max_steps:
                            break
                        
                        inputs, targets = inputs.to(self.device), targets.to(self.device)
                        
                        optimizer.zero_grad()
                        outputs = new_model(inputs, labels=targets)
                        loss = outputs['loss']
                        loss.backward()
                        optimizer.step()
                        
                        steps += 1
                    
                    stats['backfilled'] = True
                    stats['backfill_steps'] = steps
                    print(f"   âœ… Backfilled with {steps} steps")
        
        # Replace model
        self.model = new_model
        self.config.model_size = new_size
        
        # Reset optimizer and scheduler
        self.optimizer = optim.AdamW(
            self.model.parameters(),
            lr=self.config.learning_rate,
            weight_decay=self.config.weight_decay
        )
        self.scheduler = self._create_scheduler()
        
        # Reset EWC
        self.ewc = OnlineEWC(self.model, self.config.ewc_lambda)
        
        # Save new model
        self.save_checkpoint()
        
        return stats
    
    def train_on_texts(self, texts: List[str], epochs: int = 1,
                       verbose: bool = True, 
                       progress_callback: Optional[Callable] = None) -> Dict[str, Any]:
        """
        Train on a batch of texts
        
        Args:
            texts: List of text strings
            epochs: Number of epochs
            verbose: Print progress
            progress_callback: Called with progress updates
        
        Returns:
            Training statistics
        """
        if not texts:
            return {'error': 'No texts provided'}
        
        # Train tokenizer if needed
        if not self.tokenizer.is_trained:
            self.tokenizer.train(texts, verbose=verbose)
            self.tokenizer.save(self.tokenizer_path)
        else:
            # Expand vocabulary
            self.tokenizer.expand_vocabulary(texts, max_new_tokens=1000)
        
        # Tokenize
        all_token_ids = []
        for text in texts:
            try:
                ids = self.tokenizer.encode(text, add_special_tokens=True)
                all_token_ids.append(ids)
                
                # Add to replay buffer with priority based on length
                priority = min(1.0, len(ids) / 500)  # Longer = higher priority
                self.replay_buffer.add(ids, priority)
            except Exception as e:
                if verbose:
                    print(f"   âš  Tokenization error: {e}")
        
        if not all_token_ids:
            return {'error': 'No valid tokenizations'}
        
        # Create dataset
        dataset = TextDataset(
            all_token_ids,
            self.model.config.max_seq_len,
            self.tokenizer.pad_id,
            curriculum=self.config.curriculum_learning
        )
        
        if len(dataset) == 0:
            return {'error': 'Dataset empty'}
        
        # Dataloader
        dataloader = DataLoader(
            dataset,
            batch_size=self.config.batch_size,
            shuffle=not self.config.curriculum_learning,
            drop_last=True,
            num_workers=0
        )
        
        # Training loop
        self.model.train()
        total_loss = 0
        total_steps = 0
        start_time = time.time()
        
        for epoch in range(epochs):
            epoch_loss = 0
            epoch_steps = 0
            
            self.optimizer.zero_grad()
            
            for batch_idx, (inputs, targets) in enumerate(dataloader):
                inputs, targets = inputs.to(self.device), targets.to(self.device)
                
                # Mixed precision forward
                if self.scaler is not None:
                    with autocast():
                        outputs = self.model(inputs, labels=targets)
                        loss = outputs['loss']
                        
                        # EWC penalty
                        if self.ewc.is_initialized:
                            loss = loss + self.ewc.penalty()
                        
                        loss = loss / self.config.gradient_accumulation_steps
                    
                    self.scaler.scale(loss).backward()
                else:
                    outputs = self.model(inputs, labels=targets)
                    loss = outputs['loss']
                    
                    if self.ewc.is_initialized:
                        loss = loss + self.ewc.penalty()
                    
                    loss = loss / self.config.gradient_accumulation_steps
                    loss.backward()
                
                # Gradient accumulation
                if (batch_idx + 1) % self.config.gradient_accumulation_steps == 0:
                    # Gradient clipping
                    if self.scaler is not None:
                        self.scaler.unscale_(self.optimizer)
                    
                    torch.nn.utils.clip_grad_norm_(
                        self.model.parameters(),
                        self.config.max_grad_norm
                    )
                    
                    # Update
                    if self.scaler is not None:
                        self.scaler.step(self.optimizer)
                        self.scaler.update()
                    else:
                        self.optimizer.step()
                    
                    self.scheduler.step()
                    self.optimizer.zero_grad()
                    
                    self.global_step += 1
                
                # Stats
                epoch_loss += loss.item() * self.config.gradient_accumulation_steps
                epoch_steps += 1
                self.total_tokens_trained += inputs.numel()
                
                total_loss += loss.item() * self.config.gradient_accumulation_steps
                total_steps += 1
                
                # Checkpoint
                if self.global_step % self.config.save_every_steps == 0:
                    self.save_checkpoint()
                
                # Progress callback
                if progress_callback and total_steps % 10 == 0:
                    progress_callback({
                        'step': total_steps,
                        'loss': loss.item() * self.config.gradient_accumulation_steps,
                        'lr': self.scheduler.get_last_lr()[0]
                    })
            
            if verbose:
                avg_loss = epoch_loss / max(epoch_steps, 1)
                print(f"   Epoch {epoch + 1}/{epochs} - Loss: {avg_loss:.4f}")
        
        # Update EWC
        self.ewc.update_fisher(dataloader)
        
        # Save
        self.save_checkpoint()
        
        # Stats
        elapsed = time.time() - start_time
        avg_loss = total_loss / max(total_steps, 1)
        
        stats = {
            'loss': avg_loss,
            'steps': total_steps,
            'global_step': self.global_step,
            'tokens_trained': self.total_tokens_trained,
            'elapsed_seconds': elapsed,
            'tokens_per_second': (total_steps * self.config.batch_size * self.model.config.max_seq_len) / max(elapsed, 1),
            'learning_rate': self.scheduler.get_last_lr()[0]
        }
        
        self.training_history.append({
            'step': self.global_step,
            'loss': avg_loss,
            'timestamp': time.time()
        })
        
        return stats
    
    def save_checkpoint(self):
        """Save complete checkpoint"""
        self.model.save(self.model_path)
        self.tokenizer.save(self.tokenizer_path)
        self.replay_buffer.save(self.buffer_path)
        self._save_state()
    
    def generate(self, prompt: str, max_tokens: int = 100,
                 temperature: float = 0.8, top_k: int = 50,
                 top_p: float = 0.9, repetition_penalty: float = 1.1) -> str:
        """Generate text from prompt"""
        if not self.tokenizer.is_trained:
            return "Error: Tokenizer not trained."
        
        # Encode
        input_ids = self.tokenizer.encode(prompt, add_special_tokens=False)
        input_tensor = torch.tensor([input_ids], device=self.device)
        
        # Generate
        self.model.eval()
        with torch.no_grad():
            output_ids = self.model.generate(
                input_tensor,
                max_new_tokens=max_tokens,
                temperature=temperature,
                top_k=top_k,
                top_p=top_p,
                repetition_penalty=repetition_penalty,
                use_cache=True
            )
        
        # Decode
        return self.tokenizer.decode(output_ids[0].tolist())
    
    def get_stats(self) -> Dict[str, Any]:
        """Get comprehensive statistics"""
        recent_losses = [h['loss'] for h in self.training_history[-20:]]
        
        return {
            'global_step': self.global_step,
            'total_tokens_trained': self.total_tokens_trained,
            'model_params': self.model.n_params,
            'vocab_size': len(self.tokenizer),
            'replay_buffer_size': len(self.replay_buffer),
            'device': str(self.device),
            'is_training': self._is_training,
            'recent_losses': recent_losses,
            'model_size': self.config.model_size,
            'learning_rate': self.scheduler.get_last_lr()[0] if self.scheduler else self.config.learning_rate,
            'ewc_initialized': self.ewc.is_initialized,
            'n_layers': self.model.config.n_layers,
            'n_heads': self.model.config.n_heads,
            'd_model': self.model.config.d_model,
            'max_seq_len': self.model.config.max_seq_len
        }
    
    # Background training methods
    def queue_training(self, texts: List[str]):
        """Add texts to training queue"""
        self._training_queue.extend(texts)
    
    def start_background_training(self):
        """Start background training thread"""
        if self._training_thread is not None and self._training_thread.is_alive():
            return
        
        self._stop_training.clear()
        self._is_training = True
        self._training_thread = threading.Thread(target=self._background_loop, daemon=True)
        self._training_thread.start()
    
    def stop_background_training(self):
        """Stop background training"""
        self._stop_training.set()
        self._is_training = False
        if self._training_thread is not None:
            self._training_thread.join(timeout=5)
    
    def _background_loop(self):
        """Background training loop"""
        batch = []
        
        while not self._stop_training.is_set():
            while len(batch) < 10 and self._training_queue:
                batch.append(self._training_queue.popleft())
            
            if batch:
                try:
                    self.train_on_texts(batch, epochs=1, verbose=False)
                    batch = []
                except Exception as e:
                    print(f"Background training error: {e}")
                    batch = []
            else:
                time.sleep(1)


def test_trainer():
    """Test the trainer"""
    import tempfile
    
    print("=" * 60)
    print("ðŸ§ª Testing Neural Trainer v2.0")
    print("=" * 60)
    
    with tempfile.TemporaryDirectory() as tmpdir:
        config = TrainerConfig(model_size="nano", batch_size=2, gradient_accumulation_steps=1)
        trainer = NeuralTrainer(config, Path(tmpdir))
        
        # Sample texts
        texts = [
            "The quick brown fox jumps over the lazy dog.",
            "Machine learning is transforming technology.",
            "Python is popular for data science.",
            "Neural networks learn patterns from data.",
            "Transformers revolutionized NLP.",
        ] * 10
        
        # Train
        print("\nðŸ“š Training...")
        stats = trainer.train_on_texts(texts, epochs=2, verbose=True)
        print(f"   Stats: {stats}")
        
        # Generate
        print("\nðŸ”® Generating...")
        generated = trainer.generate("The quick", max_tokens=30)
        print(f"   Generated: {generated}")
        
        # Test model size change
        print("\nðŸ”„ Testing model size change...")
        change_stats = trainer.change_model_size("tiny", backfill=True)
        print(f"   Change stats: {change_stats}")
        
        # Stats
        print(f"\nðŸ“Š Final stats: {trainer.get_stats()}")
    
    print("\nâœ… Trainer test passed!")


if __name__ == "__main__":
    test_trainer()
